{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepNeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e8BDY5ORjVV",
        "outputId": "41c73d99-fe3d-4088-e534-6ab530dd3217"
      },
      "source": [
        "!pip install matplotlib-venn"
      ],
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.7/dist-packages (0.11.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from matplotlib-venn) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from matplotlib-venn) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from matplotlib-venn) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->matplotlib-venn) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYb07CVAT3pc"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "labels=[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
        "        \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mvTcIVjaOK6"
      },
      "source": [
        "Question 1: Download the fashion-MNIST dataset and plot 1 sample image for each class as shown in the grid below. Use \"from keras.datasets import fashion_mnist\" for getting the fashion mnist dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "gB2O7ss0Uif8",
        "outputId": "2fa21c58-3ae7-42e3-94d4-1264a7486264"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,5)) \n",
        "\n",
        "plottedClass =  [False for i in range(10)] \n",
        "count=0\n",
        "for i in range(25):\n",
        "    if  plottedClass[y_train[i]]==False:\n",
        "      plt.subplot(2,5,count+1).set_title(labels[y_train[i]]) \n",
        "      plt.imshow(X_train[i],cmap='gray')\n",
        "      plt.axis(\"off\")\n",
        "      plottedClass[y_train[i]]=True\n",
        "      count=count+1\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ow_YlgAjhBv"
      },
      "source": [
        "**Backpropagation code stage1.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuNCW4fYNam6"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOfgnPK_fNin",
        "outputId": "9507805c-e8bb-4f1f-a433-2538b94e14a9"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "print(\"Train data shape {} : Train label shape {}\".format(X_train.shape,Y_train.shape))\n",
        "print(\"Test data shape {} : Test label shape {}\".format(X_test.shape,Y_test.shape))\n",
        "\n",
        "#flatten the Xtrain and X_test\n",
        "X_tr=X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
        "X_ts=X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
        "\n",
        "#create one hot encoding of the labels\n",
        "Y_tr=OneHotEncoder().fit_transform(Y_train.reshape(-1,1)).toarray()\n",
        "Y_ts=OneHotEncoder().fit_transform(Y_test.reshape(-1,1)).toarray()\n",
        "\n",
        "print(\"After reshaping...\")\n",
        "\n",
        "print(\"Train data shape {} : Train label shape {}\".format(X_tr.shape,Y_tr.shape))\n",
        "print(\"Test data shape {} : Test label shape {}\".format(X_ts.shape,Y_ts.shape))\n",
        "\n",
        "#normalizing the train data...\n",
        "X_tr=X_tr/255\n",
        "X_ts=X_ts/255"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape (60000, 28, 28) : Train label shape (60000,)\n",
            "Test data shape (10000, 28, 28) : Test label shape (10000,)\n",
            "After reshaping...\n",
            "Train data shape (60000, 784) : Train label shape (60000, 10)\n",
            "Test data shape (10000, 784) : Test label shape (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vGF9yRLK8Xa"
      },
      "source": [
        "class Activation:\n",
        "\n",
        "  def Sigmoid(self,x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "  def Softmax(self,x):\n",
        "    numr=np.exp(x)\n",
        "    return numr/sum(np.exp(x))\n",
        "\n",
        "  def Relu(self,x):\n",
        "    return 1\n",
        "\n",
        "  def Derivative_Sigmoid(self,x):\n",
        "    s=1/(1+np.exp(-x))\n",
        "    return s*(1-s)\n",
        "\n",
        "  def Derivative_Relu(self,x):\n",
        "    return 1  \n",
        "  def Linear(self,x):\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERDyVQhAK-lJ"
      },
      "source": [
        "class Loss:\n",
        "\n",
        "  def CategoricalCrossEntropy(self,ypred,y):\n",
        "    class_idx=np.argmax(y,axis=0)\n",
        "    return (-1)*(np.log2(ypred[class_idx]))\n",
        "\n",
        "\n",
        "  def meansquarederror(self,ypred,y):\n",
        "\n",
        "    #check for correct squared loss function\n",
        "    return np.sum((ypred-y)**2)\n",
        "\n"
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP7KWeSsjodU"
      },
      "source": [
        "class HLayer:\n",
        "\n",
        "  def __init__(self,num_inputs,num_neurons):\n",
        "    \n",
        "    np.random.seed(2)\n",
        "    self.num_inputs=num_inputs\n",
        "    self.num_neurons=num_neurons\n",
        "    self.W=np.random.randn(num_neurons,num_inputs)\n",
        "    self.b=np.random.randn(num_neurons,)\n",
        "\n",
        "    self.del_h=np.zeros((num_neurons,))\n",
        "    self.del_a=np.zeros((num_neurons,))\n",
        "    self.delW=np.zeros((num_neurons,num_inputs))\n",
        "    self.delb=np.zeros((num_neurons,))\n",
        "\n",
        "    self.aL=0\n",
        "    self.hL=0\n",
        "\n",
        "  def Forward(self,h_L_1):\n",
        "    \n",
        "    print(\"The h(L-1) from previous layer ,\",h_L_1.shape)\n",
        "    self.aL=np.dot(self.W,h_L_1)+self.b\n",
        "    ac=Activation()\n",
        "    self.hL=ac.Sigmoid(self.aL)\n",
        "\n",
        "   \n",
        "    print(\"\\nThe h(L-1) is \",h_L_1)\n",
        "    print(\"\\nThe aL shape ,\",self.aL.shape)\n",
        "    print(\"\\nThe aL is \",self.aL)\n",
        "    print(\"\\nThe hL shape ,\",self.hL.shape)\n",
        "    print(\"\\nThe hL is \",self.hL)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  def get_gradients(self,nextW,next_aL,Prev_hL):\n",
        "      \n",
        "      self.del_h=np.dot((nextW).T,next_aL)\n",
        "      self.del_a=(self.del_h)*(Activation().Derivative_Sigmoid(self.aL))\n",
        "      self.delW=np.dot(self.del_a.reshape(-1,1),Prev_hL.reshape(1,-1))\n",
        "      self.delb=self.del_a\n",
        "\n",
        "  def show_gradients(self):\n",
        "    print(\"del_h shape \",self.del_h.shape)\n",
        "    print(\"del_h \\n\",self.del_h)\n",
        "\n",
        "    print(\"del_a shape \",self.del_a.shape)\n",
        "    print(\"del_a \\n\",self.del_a)\n",
        "\n",
        "    print(\"delW shape \",self.delW.shape)\n",
        "    print(\"delW \\n\",self.delW)\n",
        "\n",
        "    print(\"delb shape \",self.delb.shape)\n",
        "    print(\"delb \\n\",self.delW)\n",
        "\n",
        "  def update_gradients(self,eta):\n",
        "\n",
        "    self.W=self.W-eta*delW\n",
        "    self.b=self.b-eta*delb\n",
        "    \n",
        "  def reset_gradients(self):\n",
        "    \n",
        "    self.del_h=np.zeros((num_neurons,))\n",
        "    self.del_a=np.zeros((num_neurons,))\n",
        "    self.delW=np.zeros((num_neurons,num_inputs))\n",
        "    self.delb=np.zeros((num_neurons,))"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5wuAFE4Kxdp"
      },
      "source": [
        "class OPLayer:\n",
        "\n",
        "  def __init__(self,num_inputs,num_class):\n",
        "    \n",
        "    np.random.seed(2)\n",
        "    self.num_inputs=num_inputs\n",
        "    self.num_neurons=num_class\n",
        "    self.aL=0\n",
        "    self.hL=0\n",
        "    self.W=np.random.randn(num_class,num_inputs)\n",
        "    self.b=np.random.randn(num_class,)\n",
        "\n",
        "    self.del_h=np.zeros((num_class,))\n",
        "    self.del_a=np.zeros((num_class,))\n",
        "    self.delW=np.zeros((num_class,num_inputs))\n",
        "    self.delb=np.zeros((num_class,))\n",
        "\n",
        "\n",
        "  def Forward(self,h_L_1):\n",
        "    print(\"The h(L-1) from previous layer ,\",h_L_1.shape)\n",
        "    self.aL=np.dot(self.W,h_L_1)+self.b\n",
        "    ac=Activation()\n",
        "    self.hL=ac.Softmax(self.aL)\n",
        "\n",
        "    #cooment this line later..\n",
        "    print(\"\\nThe h(L-1) is \",h_L_1)\n",
        "    print(\"\\nThe aL shape ,\",self.aL.shape)\n",
        "    print(\"\\nThe aL is \",self.aL)\n",
        "    print(\"\\nThe hL shape ,\",self.hL.shape)\n",
        "    print(\"\\nThe hL is \",self.hL)\n",
        "\n",
        "\n",
        "  \n",
        "  #Y_hat is (nx10) same as Y_true\n",
        "  def get_gradients(self,Y_hat,Y,prev_hL):\n",
        "      \n",
        "      for i in range(len(Y_hat)):\n",
        "        self.del_h+=(-1/Y_hat[i][np.argmax(Y[i])]*Y[i])\n",
        "\n",
        "      for i in range(len(Y_hat)):  \n",
        "        self.del_a+=(Y_hat[i]-Y[i])\n",
        "\n",
        "      self.delW=np.dot(self.del_a.reshape(-1,1),prev_hL.reshape(1,-1))\n",
        "      self.delb=self.del_a\n",
        "\n",
        "  def show_gradients(self):\n",
        "    print(\"dely_hat shape \",self.del_h.shape)\n",
        "    print(\"dely_hat \\n\",self.del_h)\n",
        "\n",
        "    print(\"del_a shape \",self.del_a.shape)\n",
        "    print(\"del_a \\n\",self.del_a)\n",
        "\n",
        "    print(\"delW shape \",self.delW.shape)\n",
        "    print(\"delW \\n\",self.delW)\n",
        "\n",
        "    print(\"delb shape \",self.delb.shape)\n",
        "    print(\"delb \\n\",self.delW)\n",
        "\n",
        "\n",
        "\n",
        "  def update_gradients(self):\n",
        "\n",
        "    self.W=self.W-eta*delW\n",
        "    self.b=self.b-eta*delb\n",
        "\n",
        "  def reset_gradients(self):\n",
        "    self.del_h=np.zeros((num_class,))\n",
        "    self.del_a=np.zeros((num_class,))\n",
        "    self.delW=np.zeros((num_class,num_inputs))\n",
        "    self.delb=np.zeros((num_class,))\n",
        "\n"
      ],
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moWeU-tVK0tH"
      },
      "source": [
        "class IpLayer:\n",
        "\n",
        "  def __init__(self,num_neurons):\n",
        "    self.num_neurons=num_neurons\n",
        "    self.hL=0\n",
        "\n",
        "\n",
        "  def Forward(self,x):\n",
        "    self.hL=x\n",
        "    print(\"for input layer the hL shape \",self.hL.shape)\n",
        "\n"
      ],
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKOYvpEuK5Tv"
      },
      "source": [
        "class NN:\n",
        "\n",
        "  def __init__(self,input_shape,num_hlayers,neurons,activation_hl,activation_op,output_shape):\n",
        "\n",
        "    self.input_shape=input_shape\n",
        "    self.output_shape=output_shape\n",
        "    self.num_hlayers=num_hlayers\n",
        "    self.neurons=neurons\n",
        "    self.activation_hl=activation_hl\n",
        "    self.activation_op=activation_op\n",
        "    self.Layers=[]\n",
        "    self.eta=1e-4\n",
        "    self.loss=0.0\n",
        "\n",
        "    #used to store the predicted probabilities of passed data\n",
        "    self.Y_hat=[]\n",
        "\n",
        "  \n",
        "  def create_architecture(self):\n",
        "\n",
        "    #create input layer\n",
        "    self.Layers.append(IpLayer(self.input_shape))\n",
        "\n",
        "    #hidden layers..\n",
        "    for layer in range(1,self.num_hlayers+1):\n",
        "      \n",
        "      ip_shape=self.Layers[layer-1].num_neurons\n",
        "      self.Layers.append(HLayer(ip_shape,self.neurons[layer-1]))\n",
        "\n",
        "    #output layer..\n",
        "\n",
        "    self.Layers.append(OPLayer(self.Layers[self.num_hlayers].num_neurons,self.output_shape))  \n",
        "     \n",
        "\n",
        "  def Feed_Forward(self,X_train,Y_train):\n",
        "\n",
        "\n",
        "    #pass whole data to the NN to get the loss:\n",
        "    print(\"Feeding the data one by one to the NN...\")\n",
        "    self.loss=0\n",
        "    for i in range(X_train.shape[0]):\n",
        "\n",
        "      print(\"\\n passing  datapoint..{}\".format(i))\n",
        "      #get the data in input layer\n",
        "      self.Layers[0].Forward(X_train[i])\n",
        "\n",
        "      #pass the data to the hl+ol\n",
        "\n",
        "      for j in range(1,self.num_hlayers+2):\n",
        "\n",
        "        print(\"For Layer :\\n\",j)\n",
        "        h_L_1=self.Layers[j-1].hL\n",
        "\n",
        "        self.Layers[j].Forward(h_L_1)\n",
        "\n",
        "        print(\"**\"*50)\n",
        "      \n",
        "      #calculate the loss for this datapoint:\n",
        "      ypred=self.Layers[self.num_hlayers+1].hL\n",
        "      self.Y_hat.append(ypred)\n",
        "      self.loss+=Loss().CategoricalCrossEntropy(ypred,Y_train[0])\n",
        "\n",
        "\n",
        "      print(\"\\nloss upto datapoint {} is {}\".format(i,self.loss))\n",
        "    \n",
        "    print(\"Loss is : \",self.loss)\n",
        "\n",
        "  def Back_Propogation(self,Y):\n",
        "\n",
        "    #get gradients for output layer first..\n",
        "    prev_hL=self.Layers[self.num_hlayers].hL\n",
        "    self.Layers[self.num_hlayers+1].get_gradients(self.Y_hat,Y,prev_hL)\n",
        "\n",
        "    #getting gradients for hidden layers..\n",
        "    for i in range(self.num_hlayers,0,-1):\n",
        "\n",
        "      prev_hL=self.Layers[i-1].hL\n",
        "      next_W=self.Layers[i+1].W\n",
        "      next_aL=self.Layers[i+1].aL\n",
        "      self.Layers[i].get_gradients(next_W,next_aL,prev_hL)\n",
        "\n",
        "      \n",
        "  #update gradients for each layer...\n",
        "  def update_gradients(self):\n",
        "    \n",
        "    for i in range(1,self.num_hlayers+2):\n",
        "      self.Layers[i].update_gradients(self.eta)\n",
        "\n",
        "  #reset gradients for each layer...\n",
        "  def reset_gradients(self):\n",
        "\n",
        "    for i in range(1,self.num_hlayers+2):\n",
        "      self.Layers[i].reset_gradients()\n",
        "    \n",
        "    self.loss=0"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "146tgXB7XA4V"
      },
      "source": [
        "X_sample=X_tr[:5]\n",
        "Y_sample=Y_tr[:5]"
      ],
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49BNAGPuK7Pp",
        "outputId": "912a2a13-da85-47f6-e322-1f9e0f790ed1"
      },
      "source": [
        "#### DEBUGGING CELL ####\n",
        "arch1=NN(784,2,[20,15],'sigmoid','softmax',10)\n",
        "arch1.create_architecture()\n",
        "LTest=arch1.Layers\n",
        "for l in range(len(LTest)):\n",
        "\n",
        "  print(\"LAYER NUMBER: \",l)\n",
        "  print(\"num_neurons :\",LTest[l].num_neurons)\n",
        "\n",
        "  if l!=0:\n",
        "    print(\"number of inputs :\",LTest[l].num_inputs)\n",
        "    print(\"shape of weights :\",LTest[l].W.shape)\n",
        "    print(\"shape of biases :\",LTest[l].b.shape)\n",
        "    print(\"shape of delW :\",LTest[l].delW.shape)\n",
        "    print(\"shape of delb :\",LTest[l].delb.shape)\n",
        "    print(\"shape of delh :\",LTest[l].del_h.shape)\n",
        "    print(\"shape of dela :\",LTest[l].del_a.shape)\n",
        "  \n",
        "  print(\"--\"*50)\n"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LAYER NUMBER:  0\n",
            "num_neurons : 784\n",
            "----------------------------------------------------------------------------------------------------\n",
            "LAYER NUMBER:  1\n",
            "num_neurons : 20\n",
            "number of inputs : 784\n",
            "shape of weights : (20, 784)\n",
            "shape of biases : (20,)\n",
            "shape of delW : (20, 784)\n",
            "shape of delb : (20,)\n",
            "shape of delh : (20,)\n",
            "shape of dela : (20,)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "LAYER NUMBER:  2\n",
            "num_neurons : 15\n",
            "number of inputs : 20\n",
            "shape of weights : (15, 20)\n",
            "shape of biases : (15,)\n",
            "shape of delW : (15, 20)\n",
            "shape of delb : (15,)\n",
            "shape of delh : (15,)\n",
            "shape of dela : (15,)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "LAYER NUMBER:  3\n",
            "num_neurons : 10\n",
            "number of inputs : 15\n",
            "shape of weights : (10, 15)\n",
            "shape of biases : (10,)\n",
            "shape of delW : (10, 15)\n",
            "shape of delb : (10,)\n",
            "shape of delh : (10,)\n",
            "shape of dela : (10,)\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HFqAon0zbE1",
        "outputId": "f9cd08ca-1d9d-4065-edd2-6690c24071c0"
      },
      "source": [
        "arch1.Feed_Forward(X_sample,Y_sample)"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feeding the data one by one to the NN...\n",
            "\n",
            " passing  datapoint..0\n",
            "for input layer the hL shape  (784,)\n",
            "For Layer :\n",
            " 1\n",
            "The h(L-1) from previous layer , (784,)\n",
            "\n",
            "The h(L-1) is  [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
            " 0.         0.00392157 0.01568627 0.         0.         0.\n",
            " 0.         0.00392157 0.00392157 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.01176471 0.\n",
            " 0.14117647 0.53333333 0.49803922 0.24313725 0.21176471 0.\n",
            " 0.         0.         0.00392157 0.01176471 0.01568627 0.\n",
            " 0.         0.01176471 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.02352941 0.         0.4        0.8\n",
            " 0.69019608 0.5254902  0.56470588 0.48235294 0.09019608 0.\n",
            " 0.         0.         0.         0.04705882 0.03921569 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
            " 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
            " 0.30196078 0.50980392 0.28235294 0.05882353 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.00392157 0.         0.27058824\n",
            " 0.81176471 0.8745098  0.85490196 0.84705882 0.84705882 0.63921569\n",
            " 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804\n",
            " 0.6745098  0.25882353 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00392157\n",
            " 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392\n",
            " 0.91372549 0.89803922 0.8745098  0.8745098  0.84313725 0.83529412\n",
            " 0.64313725 0.49803922 0.48235294 0.76862745 0.89803922 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
            " 0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
            " 0.8745098  0.96078431 0.67843137 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.75686275\n",
            " 0.89411765 0.85490196 0.83529412 0.77647059 0.70588235 0.83137255\n",
            " 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118\n",
            " 0.79215686 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00392157\n",
            " 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255\n",
            " 0.85490196 0.75294118 0.6627451  0.89019608 0.81568627 0.85490196\n",
            " 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.02352941 0.\n",
            " 0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
            " 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
            " 0.96078431 0.46666667 0.65490196 0.21960784 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.01568627 0.         0.         0.21568627 0.9254902\n",
            " 0.89411765 0.90196078 0.89411765 0.94117647 0.90980392 0.83529412\n",
            " 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784\n",
            " 0.36078431 0.         0.         0.         0.00392157 0.01568627\n",
            " 0.02352941 0.02745098 0.00784314 0.         0.         0.\n",
            " 0.         0.         0.92941176 0.88627451 0.85098039 0.8745098\n",
            " 0.87058824 0.85882353 0.87058824 0.86666667 0.84705882 0.8745098\n",
            " 0.89803922 0.84313725 0.85490196 1.         0.30196078 0.\n",
            " 0.         0.01176471 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.24313725 0.56862745 0.8\n",
            " 0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
            " 0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
            " 0.87843137 0.95686275 0.62352941 0.         0.         0.\n",
            " 0.         0.         0.07058824 0.17254902 0.32156863 0.41960784\n",
            " 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451\n",
            " 0.78431373 0.80392157 0.82745098 0.90196078 0.87843137 0.91764706\n",
            " 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333\n",
            " 0.84313725 0.         0.         0.22352941 0.73333333 0.81568627\n",
            " 0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569\n",
            " 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275\n",
            " 0.80784314 0.8745098  1.         1.         0.86666667 0.91764706\n",
            " 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.\n",
            " 0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
            " 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
            " 0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
            " 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
            " 0.87058824 0.89411765 0.88235294 0.         0.38431373 0.91372549\n",
            " 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706\n",
            " 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804\n",
            " 0.25490196 0.28627451 0.41568627 0.45882353 0.65882353 0.85882353\n",
            " 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137\n",
            " 0.89803922 0.11372549 0.29411765 0.8        0.83137255 0.8\n",
            " 0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902\n",
            " 0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588\n",
            " 0.89019608 0.96078431 0.9372549  0.8745098  0.85490196 0.83137255\n",
            " 0.81960784 0.87058824 0.8627451  0.86666667 0.90196078 0.2627451\n",
            " 0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
            " 0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
            " 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
            " 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
            " 0.70980392 0.80392157 0.80784314 0.45098039 0.         0.47843137\n",
            " 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745\n",
            " 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941\n",
            " 0.78431373 0.76862745 0.76078431 0.74901961 0.76470588 0.74901961\n",
            " 0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765\n",
            " 0.82352941 0.36078431 0.         0.         0.29019608 0.74117647\n",
            " 0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392\n",
            " 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059\n",
            " 0.8        0.81960784 0.82352941 0.82352941 0.82745098 0.7372549\n",
            " 0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.\n",
            " 0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
            " 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
            " 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
            " 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
            " 0.38823529 0.22745098 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.15686275\n",
            " 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "The aL shape , (20,)\n",
            "\n",
            "The aL is  [-30.61323288  -2.30113729  21.75861234   1.52036928 -22.6745983\n",
            "  18.76595387  -2.65808082 -32.71646254  10.01899006 -12.26742565\n",
            "   3.4290251    6.42948623  -6.10357198  12.62962898  11.95193256\n",
            "  17.1025674    9.43251451  -2.86498778  24.57870855  11.82758742]\n",
            "\n",
            "The hL shape , (20,)\n",
            "\n",
            "The hL is  [5.06806164e-14 9.10288153e-02 1.00000000e+00 8.20592853e-01\n",
            " 1.42084622e-10 9.99999993e-01 6.54926959e-02 6.18615576e-15\n",
            " 9.99955456e-01 4.70243382e-06 9.68599430e-01 9.98389319e-01\n",
            " 2.22988702e-03 9.99996726e-01 9.99993553e-01 9.99999963e-01\n",
            " 9.99919929e-01 5.39117306e-02 1.00000000e+00 9.99992700e-01]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 2\n",
            "The h(L-1) from previous layer , (20,)\n",
            "\n",
            "The h(L-1) is  [5.06806164e-14 9.10288153e-02 1.00000000e+00 8.20592853e-01\n",
            " 1.42084622e-10 9.99999993e-01 6.54926959e-02 6.18615576e-15\n",
            " 9.99955456e-01 4.70243382e-06 9.68599430e-01 9.98389319e-01\n",
            " 2.22988702e-03 9.99996726e-01 9.99993553e-01 9.99999963e-01\n",
            " 9.99919929e-01 5.39117306e-02 1.00000000e+00 9.99992700e-01]\n",
            "\n",
            "The aL shape , (15,)\n",
            "\n",
            "The aL is  [-0.8381127   3.12785136 -2.62600599 -3.18222556  1.10899949 -0.75481155\n",
            "  1.70218681  0.87771536  4.25886814  2.73396331 -4.36654464 -7.1578875\n",
            " -0.38969416 -4.5925332  -6.93102866]\n",
            "\n",
            "The hL shape , (15,)\n",
            "\n",
            "The hL is  [3.01932420e-01 9.58027078e-01 6.74833575e-02 3.98401127e-02\n",
            " 7.51942539e-01 3.19773793e-01 8.45820129e-01 7.06348564e-01\n",
            " 9.86058809e-01 9.39001242e-01 1.25358873e-02 7.78091920e-04\n",
            " 4.03790926e-01 1.00256403e-02 9.76041769e-04]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 3\n",
            "The h(L-1) from previous layer , (15,)\n",
            "\n",
            "The h(L-1) is  [3.01932420e-01 9.58027078e-01 6.74833575e-02 3.98401127e-02\n",
            " 7.51942539e-01 3.19773793e-01 8.45820129e-01 7.06348564e-01\n",
            " 9.86058809e-01 9.39001242e-01 1.25358873e-02 7.78091920e-04\n",
            " 4.03790926e-01 1.00256403e-02 9.76041769e-04]\n",
            "\n",
            "The aL shape , (10,)\n",
            "\n",
            "The aL is  [-3.61099504 -2.16081761  1.98032992 -1.26213295 -1.69684659 -1.37407477\n",
            " -0.44218231 -0.58810537  1.79349378 -2.27282537]\n",
            "\n",
            "The hL shape , (10,)\n",
            "\n",
            "The hL is  [0.00175279 0.00747368 0.46990725 0.01835813 0.01188597 0.01641393\n",
            " 0.04168007 0.03602093 0.38982549 0.00668175]\n",
            "****************************************************************************************************\n",
            "\n",
            "loss upto datapoint 0 is 7.225558111845053\n",
            "\n",
            " passing  datapoint..1\n",
            "for input layer the hL shape  (784,)\n",
            "For Layer :\n",
            " 1\n",
            "The h(L-1) from previous layer , (784,)\n",
            "\n",
            "The h(L-1) is  [0.         0.         0.         0.         0.         0.00392157\n",
            " 0.         0.         0.         0.         0.16078431 0.7372549\n",
            " 0.40392157 0.21176471 0.18823529 0.16862745 0.34117647 0.65882353\n",
            " 0.52156863 0.0627451  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00392157 0.         0.         0.         0.19215686\n",
            " 0.53333333 0.85882353 0.84705882 0.89411765 0.9254902  1.\n",
            " 1.         1.         1.         0.85098039 0.84313725 0.99607843\n",
            " 0.90588235 0.62745098 0.17647059 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.69019608 0.87058824 0.87843137 0.83137255\n",
            " 0.79607843 0.77647059 0.76862745 0.78431373 0.84313725 0.8\n",
            " 0.79215686 0.78823529 0.78823529 0.78823529 0.81960784 0.85490196\n",
            " 0.87843137 0.64313725 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.7372549\n",
            " 0.85882353 0.78431373 0.77647059 0.79215686 0.77647059 0.78039216\n",
            " 0.78039216 0.78823529 0.76862745 0.77647059 0.77647059 0.78431373\n",
            " 0.78431373 0.78431373 0.78431373 0.78823529 0.78431373 0.88235294\n",
            " 0.16078431 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.2        0.85882353 0.78039216 0.79607843\n",
            " 0.79607843 0.83137255 0.93333333 0.97254902 0.98039216 0.96078431\n",
            " 0.97647059 0.96470588 0.96862745 0.98823529 0.97254902 0.92156863\n",
            " 0.81176471 0.79607843 0.79607843 0.87058824 0.54901961 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.45490196 0.88627451 0.80784314 0.8        0.81176471 0.8\n",
            " 0.39607843 0.29411765 0.18431373 0.28627451 0.18823529 0.19607843\n",
            " 0.17647059 0.2        0.24705882 0.44313725 0.87058824 0.79215686\n",
            " 0.80784314 0.8627451  0.87843137 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.78431373 0.87058824\n",
            " 0.81960784 0.79607843 0.84313725 0.78431373 0.         0.2745098\n",
            " 0.38431373 0.         0.40392157 0.23137255 0.26666667 0.27843137\n",
            " 0.19215686 0.         0.85882353 0.80784314 0.83921569 0.82352941\n",
            " 0.98039216 0.14901961 0.         0.         0.         0.\n",
            " 0.         0.         0.96862745 0.85490196 0.83137255 0.82352941\n",
            " 0.84313725 0.83921569 0.         0.99607843 0.95294118 0.54509804\n",
            " 1.         0.68235294 0.98431373 1.         0.80392157 0.\n",
            " 0.84313725 0.85098039 0.83921569 0.81568627 0.8627451  0.37254902\n",
            " 0.         0.         0.         0.         0.         0.17647059\n",
            " 0.88627451 0.83921569 0.83921569 0.84313725 0.87843137 0.80392157\n",
            " 0.         0.16470588 0.1372549  0.23529412 0.0627451  0.06666667\n",
            " 0.04705882 0.05098039 0.2745098  0.         0.74117647 0.84705882\n",
            " 0.83137255 0.80784314 0.83137255 0.61176471 0.         0.\n",
            " 0.         0.         0.         0.64313725 0.92156863 0.83921569\n",
            " 0.82745098 0.8627451  0.84705882 0.78823529 0.20392157 0.27843137\n",
            " 0.34901961 0.36862745 0.3254902  0.30588235 0.2745098  0.29803922\n",
            " 0.36078431 0.34117647 0.80784314 0.81176471 0.87058824 0.83529412\n",
            " 0.85882353 0.81568627 0.         0.         0.         0.\n",
            " 0.         0.41568627 0.73333333 0.8745098  0.92941176 0.97254902\n",
            " 0.82745098 0.77647059 0.98823529 0.98039216 0.97254902 0.96078431\n",
            " 0.97254902 0.98823529 0.99215686 0.98039216 0.98823529 0.9372549\n",
            " 0.78823529 0.83137255 0.88235294 0.84313725 0.75686275 0.44313725\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.06666667 0.21176471 0.62352941 0.87058824 0.75686275\n",
            " 0.81568627 0.75294118 0.77254902 0.78431373 0.78431373 0.78431373\n",
            " 0.78431373 0.78823529 0.79607843 0.76470588 0.82352941 0.64705882\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.18431373 0.88235294 0.75294118 0.83921569 0.79607843\n",
            " 0.80784314 0.8        0.8        0.80392157 0.80784314 0.8\n",
            " 0.83137255 0.77254902 0.85490196 0.41960784 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00392157 0.02352941 0.         0.18039216\n",
            " 0.83137255 0.76470588 0.83137255 0.79215686 0.80784314 0.80392157\n",
            " 0.8        0.80392157 0.80784314 0.8        0.83137255 0.78431373\n",
            " 0.85490196 0.35686275 0.         0.01176471 0.00392157 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00392157 0.         0.04313725 0.77254902 0.78039216\n",
            " 0.80392157 0.79215686 0.80392157 0.80784314 0.8        0.80392157\n",
            " 0.81176471 0.8        0.80392157 0.80392157 0.85490196 0.30196078\n",
            " 0.         0.01960784 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.01176471\n",
            " 0.         0.00784314 0.74901961 0.77647059 0.78823529 0.80392157\n",
            " 0.80784314 0.80392157 0.80392157 0.80784314 0.81960784 0.80784314\n",
            " 0.78039216 0.81960784 0.85882353 0.29019608 0.         0.01960784\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.00784314 0.         0.\n",
            " 0.7372549  0.77254902 0.78431373 0.81176471 0.81176471 0.8\n",
            " 0.81176471 0.81176471 0.82352941 0.81568627 0.77647059 0.81176471\n",
            " 0.86666667 0.28235294 0.         0.01568627 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00784314 0.         0.         0.84313725 0.77647059\n",
            " 0.79607843 0.80784314 0.81568627 0.80392157 0.81176471 0.81176471\n",
            " 0.82352941 0.81568627 0.78431373 0.79215686 0.87058824 0.29411765\n",
            " 0.         0.01568627 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00392157\n",
            " 0.         0.         0.83137255 0.77647059 0.81960784 0.80784314\n",
            " 0.81960784 0.80784314 0.81568627 0.81176471 0.82745098 0.80784314\n",
            " 0.80392157 0.77647059 0.86666667 0.31372549 0.         0.01176471\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.00392157 0.         0.\n",
            " 0.8        0.78823529 0.80392157 0.81568627 0.81176471 0.80392157\n",
            " 0.82745098 0.80392157 0.82352941 0.82352941 0.81960784 0.76470588\n",
            " 0.86666667 0.37647059 0.         0.01176471 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00392157 0.         0.         0.79215686 0.78823529\n",
            " 0.80392157 0.81960784 0.81176471 0.80392157 0.83529412 0.80784314\n",
            " 0.82352941 0.81960784 0.82352941 0.76078431 0.85098039 0.41176471\n",
            " 0.         0.00784314 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00392157\n",
            " 0.         0.         0.8        0.8        0.80392157 0.81568627\n",
            " 0.81176471 0.80392157 0.84313725 0.81176471 0.82352941 0.81568627\n",
            " 0.82745098 0.75686275 0.83529412 0.45098039 0.         0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.8        0.81176471 0.81176471 0.81568627 0.80784314 0.80784314\n",
            " 0.84313725 0.82352941 0.82352941 0.81176471 0.83137255 0.76470588\n",
            " 0.82352941 0.4627451  0.         0.00784314 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00392157 0.         0.         0.77647059 0.81568627\n",
            " 0.81568627 0.81568627 0.8        0.81176471 0.83137255 0.83137255\n",
            " 0.82352941 0.81176471 0.82745098 0.76862745 0.81176471 0.4745098\n",
            " 0.         0.00392157 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00392157\n",
            " 0.         0.         0.77647059 0.82352941 0.81176471 0.81568627\n",
            " 0.80784314 0.81960784 0.83529412 0.83137255 0.82745098 0.81176471\n",
            " 0.82352941 0.77254902 0.81176471 0.48627451 0.         0.00392157\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.6745098  0.82352941 0.79607843 0.78823529 0.78039216 0.8\n",
            " 0.81176471 0.80392157 0.8        0.78823529 0.80392157 0.77254902\n",
            " 0.80784314 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.7372549  0.86666667\n",
            " 0.83921569 0.91764706 0.9254902  0.93333333 0.95686275 0.95686275\n",
            " 0.95686275 0.94117647 0.95294118 0.83921569 0.87843137 0.63529412\n",
            " 0.         0.00784314 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00392157\n",
            " 0.         0.         0.54509804 0.57254902 0.50980392 0.52941176\n",
            " 0.52941176 0.5372549  0.49019608 0.48627451 0.49019608 0.4745098\n",
            " 0.46666667 0.44705882 0.50980392 0.29803922 0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "The aL shape , (20,)\n",
            "\n",
            "The aL is  [-10.53240807 -16.70991583  26.60474527   8.71642892 -27.90216906\n",
            " -11.92219417   4.64307874 -24.89199071 -22.64317214  -5.13824684\n",
            "   4.45453754  -5.32472735  -9.42970083  15.40659701 -18.55107243\n",
            "  15.55331476  29.88739047  19.77150107  22.59476387  -3.39852287]\n",
            "\n",
            "The hL shape , (20,)\n",
            "\n",
            "The hL is  [2.66576410e-05 5.53319198e-08 1.00000000e+00 9.99836156e-01\n",
            " 7.62503683e-13 6.64131343e-06 9.90463805e-01 1.54719762e-11\n",
            " 1.46620699e-10 5.83373604e-03 9.88507909e-01 4.84607968e-03\n",
            " 8.02967722e-05 9.99999796e-01 8.77751555e-09 9.99999824e-01\n",
            " 1.00000000e+00 9.99999997e-01 1.00000000e+00 3.23416606e-02]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 2\n",
            "The h(L-1) from previous layer , (20,)\n",
            "\n",
            "The h(L-1) is  [2.66576410e-05 5.53319198e-08 1.00000000e+00 9.99836156e-01\n",
            " 7.62503683e-13 6.64131343e-06 9.90463805e-01 1.54719762e-11\n",
            " 1.46620699e-10 5.83373604e-03 9.88507909e-01 4.84607968e-03\n",
            " 8.02967722e-05 9.99999796e-01 8.77751555e-09 9.99999824e-01\n",
            " 1.00000000e+00 9.99999997e-01 1.00000000e+00 3.23416606e-02]\n",
            "\n",
            "The aL shape , (15,)\n",
            "\n",
            "The aL is  [ 0.11784805  0.12047246  1.59014832 -2.17434892  7.69783834  0.49078659\n",
            "  1.40869787  0.0947753   0.26891253  1.79944762  0.13376598 -4.33590772\n",
            " -2.03329868 -0.73072011 -4.18458364]\n",
            "\n",
            "The hL shape , (15,)\n",
            "\n",
            "The hL is  [0.52942796 0.53008174 0.83063697 0.10207773 0.9995464  0.62029172\n",
            " 0.80356048 0.5236761  0.56682591 0.85808168 0.53339172 0.01292085\n",
            " 0.11575087 0.32503672 0.01500012]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 3\n",
            "The h(L-1) from previous layer , (15,)\n",
            "\n",
            "The h(L-1) is  [0.52942796 0.53008174 0.83063697 0.10207773 0.9995464  0.62029172\n",
            " 0.80356048 0.5236761  0.56682591 0.85808168 0.53339172 0.01292085\n",
            " 0.11575087 0.32503672 0.01500012]\n",
            "\n",
            "The aL shape , (10,)\n",
            "\n",
            "The aL is  [-5.22509665 -1.53659032  0.65264468 -0.65817649 -2.4391175  -2.29641973\n",
            "  0.31767972  0.49522995  1.98413932  0.65640764]\n",
            "\n",
            "The hL shape , (10,)\n",
            "\n",
            "The hL is  [3.57174706e-04 1.42816584e-02 1.27512077e-01 3.43770750e-02\n",
            " 5.79183347e-03 6.68019166e-03 9.12174419e-02 1.08939901e-01\n",
            " 4.82849843e-01 1.27992804e-01]\n",
            "****************************************************************************************************\n",
            "\n",
            "loss upto datapoint 1 is 10.19142350205081\n",
            "\n",
            " passing  datapoint..2\n",
            "for input layer the hL shape  (784,)\n",
            "For Layer :\n",
            " 1\n",
            "The h(L-1) from previous layer , (784,)\n",
            "\n",
            "The h(L-1) is  [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.08627451 0.4627451  0.09411765\n",
            " 0.         0.         0.         0.         0.         0.18823529\n",
            " 0.34509804 0.01960784 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.04705882 0.39215686 0.83137255 0.80392157 0.7254902  0.70196078\n",
            " 0.67843137 0.72941176 0.75686275 0.86666667 0.55686275 0.33333333\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.33333333\n",
            " 0.29803922 0.78039216 0.88235294 0.97254902 1.         0.93333333\n",
            " 0.88627451 0.61568627 0.26666667 0.31372549 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.35686275 0.27058824 0.35686275\n",
            " 0.78823529 0.85490196 0.88235294 0.81960784 0.61960784 0.23921569\n",
            " 0.36470588 0.28235294 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.30980392 0.34901961 0.23921569 0.23137255 0.34117647\n",
            " 0.42352941 0.29411765 0.21960784 0.29803922 0.38039216 0.28627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.29411765\n",
            " 0.34901961 0.31372549 0.31372549 0.2627451  0.24705882 0.28627451\n",
            " 0.3254902  0.31372549 0.37647059 0.28235294 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.30196078 0.34509804 0.30196078\n",
            " 0.31372549 0.3254902  0.3254902  0.3254902  0.3254902  0.31764706\n",
            " 0.37254902 0.29803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.34901961 0.37647059 0.31372549 0.3254902  0.31764706\n",
            " 0.32941176 0.33333333 0.33333333 0.33333333 0.38039216 0.32941176\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.36470588\n",
            " 0.38039216 0.31764706 0.33333333 0.32941176 0.33333333 0.34117647\n",
            " 0.34509804 0.32941176 0.38823529 0.34117647 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.37254902 0.34117647 0.32941176\n",
            " 0.34117647 0.34509804 0.33333333 0.34117647 0.34117647 0.32941176\n",
            " 0.36078431 0.34117647 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.38039216 0.34117647 0.34117647 0.33333333 0.34509804\n",
            " 0.34117647 0.34117647 0.34117647 0.34509804 0.33333333 0.41960784\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.06666667 0.39215686\n",
            " 0.34509804 0.34117647 0.34117647 0.34509804 0.34117647 0.34117647\n",
            " 0.33333333 0.34901961 0.30196078 0.4627451  0.03137255 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.03921569 0.36470588 0.34117647 0.34117647\n",
            " 0.34117647 0.34117647 0.34117647 0.34509804 0.34117647 0.34901961\n",
            " 0.31372549 0.40392157 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.03529412 0.37647059 0.34117647 0.34117647 0.34117647 0.34117647\n",
            " 0.34117647 0.34509804 0.34117647 0.34509804 0.34117647 0.40392157\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.04705882 0.37647059\n",
            " 0.33333333 0.34117647 0.34117647 0.34117647 0.33333333 0.34117647\n",
            " 0.34117647 0.34509804 0.34901961 0.39215686 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.07843137 0.37254902 0.32941176 0.34509804\n",
            " 0.33333333 0.34117647 0.34509804 0.34509804 0.34509804 0.34901961\n",
            " 0.34509804 0.38823529 0.03137255 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.08235294 0.37647059 0.33333333 0.34117647 0.33333333 0.34509804\n",
            " 0.34509804 0.34509804 0.34509804 0.34901961 0.34901961 0.38823529\n",
            " 0.03921569 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.09411765 0.37647059\n",
            " 0.33333333 0.34117647 0.33333333 0.34117647 0.34509804 0.34509804\n",
            " 0.34901961 0.34509804 0.35686275 0.4        0.05490196 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09803922 0.36470588 0.32941176 0.34509804\n",
            " 0.34117647 0.34117647 0.34117647 0.34117647 0.34117647 0.34901961\n",
            " 0.35686275 0.40392157 0.11372549 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.11764706 0.37254902 0.33333333 0.34509804 0.34509804 0.34117647\n",
            " 0.34117647 0.34117647 0.34117647 0.34901961 0.34509804 0.4\n",
            " 0.14509804 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13333333 0.37647059\n",
            " 0.34509804 0.34117647 0.34117647 0.34117647 0.34117647 0.34117647\n",
            " 0.34117647 0.33333333 0.33333333 0.38039216 0.14901961 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.15686275 0.37647059 0.34117647 0.33333333\n",
            " 0.34117647 0.34117647 0.34117647 0.34117647 0.34117647 0.33333333\n",
            " 0.32941176 0.36078431 0.19215686 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.18039216 0.37254902 0.3254902  0.32941176 0.34117647 0.34117647\n",
            " 0.34117647 0.34117647 0.34117647 0.34117647 0.32941176 0.34117647\n",
            " 0.32941176 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.28235294 0.37254902\n",
            " 0.33333333 0.32941176 0.33333333 0.34509804 0.34117647 0.34117647\n",
            " 0.34901961 0.34117647 0.33333333 0.3254902  0.24705882 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.25098039 0.39215686 0.32941176 0.34117647\n",
            " 0.34509804 0.33333333 0.34509804 0.34509804 0.32941176 0.34117647\n",
            " 0.3254902  0.37254902 0.20784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.03921569 0.4        0.39215686 0.35686275 0.35686275 0.34901961\n",
            " 0.33333333 0.32941176 0.32941176 0.34117647 0.42352941 0.41568627\n",
            " 0.05490196 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.03137255\n",
            " 0.28627451 0.36470588 0.40784314 0.41960784 0.40392157 0.40392157\n",
            " 0.41568627 0.4        0.29411765 0.03921569 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00392157 0.         0.         0.\n",
            " 0.07058824 0.16470588 0.22352941 0.21960784 0.1254902  0.03137255\n",
            " 0.         0.         0.00392157 0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "The aL shape , (20,)\n",
            "\n",
            "The aL is  [ -8.57594831  -8.07460075   0.39742551   4.23600868 -14.28331981\n",
            "   0.55003899   2.25762551  -9.55549174 -14.36655332   2.70453466\n",
            "   1.37633146   3.7495862   -4.06167256   9.01621444   3.63904428\n",
            "   8.01704531   7.65635044   6.19486257  13.72668392  -0.21103013]\n",
            "\n",
            "The hL shape , (20,)\n",
            "\n",
            "The hL is  [1.88551970e-04 3.11250642e-04 5.98068954e-01 9.85741047e-01\n",
            " 6.26372602e-07 6.34144637e-01 9.05306270e-01 7.08063024e-05\n",
            " 5.76348169e-07 9.37293694e-01 7.98401171e-01 9.77013339e-01\n",
            " 1.69286781e-02 9.99878590e-01 9.74395378e-01 9.99670316e-01\n",
            " 9.99527193e-01 9.97964269e-01 9.99998907e-01 4.47437391e-01]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 2\n",
            "The h(L-1) from previous layer , (20,)\n",
            "\n",
            "The h(L-1) is  [1.88551970e-04 3.11250642e-04 5.98068954e-01 9.85741047e-01\n",
            " 6.26372602e-07 6.34144637e-01 9.05306270e-01 7.08063024e-05\n",
            " 5.76348169e-07 9.37293694e-01 7.98401171e-01 9.77013339e-01\n",
            " 1.69286781e-02 9.99878590e-01 9.74395378e-01 9.99670316e-01\n",
            " 9.99527193e-01 9.97964269e-01 9.99998907e-01 4.47437391e-01]\n",
            "\n",
            "The aL shape , (15,)\n",
            "\n",
            "The aL is  [ 2.18107099  2.55905974  1.2163123  -2.36833539  4.4960619   0.50397188\n",
            "  0.01745411  2.1523385  -0.39399234  2.28534913 -1.03680529 -4.63100768\n",
            " -2.85263858 -3.47097082 -3.90105692]\n",
            "\n",
            "The hL shape , (15,)\n",
            "\n",
            "The hL is  [0.89853675 0.9281798  0.77141393 0.08561937 0.98897018 0.62339228\n",
            " 0.50436342 0.8958871  0.4027566  0.90765637 0.26176689 0.00965089\n",
            " 0.05454509 0.03014958 0.01981976]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 3\n",
            "The h(L-1) from previous layer , (15,)\n",
            "\n",
            "The h(L-1) is  [0.89853675 0.9281798  0.77141393 0.08561937 0.98897018 0.62339228\n",
            " 0.50436342 0.8958871  0.4027566  0.90765637 0.26176689 0.00965089\n",
            " 0.05454509 0.03014958 0.01981976]\n",
            "\n",
            "The aL shape , (10,)\n",
            "\n",
            "The aL is  [-5.59847506 -0.97932993  0.84032145 -0.96679142 -2.83732375 -2.21516016\n",
            " -0.20953988  1.52643697  0.84484406 -0.06269492]\n",
            "\n",
            "The hL shape , (10,)\n",
            "\n",
            "The hL is  [3.10593953e-04 3.14964957e-02 1.94324155e-01 3.18939010e-02\n",
            " 4.91298880e-03 9.15267384e-03 6.80107877e-02 3.85925053e-01\n",
            " 1.95204998e-01 7.87683529e-02]\n",
            "****************************************************************************************************\n",
            "\n",
            "loss upto datapoint 2 is 13.857663584181322\n",
            "\n",
            " passing  datapoint..3\n",
            "for input layer the hL shape  (784,)\n",
            "For Layer :\n",
            " 1\n",
            "The h(L-1) from previous layer , (784,)\n",
            "\n",
            "The h(L-1) is  [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.12941176 0.37647059 0.68627451 0.61176471\n",
            " 0.25098039 0.05490196 0.21176471 0.5372549  0.8        0.76078431\n",
            " 0.4        0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.28627451 0.72941176\n",
            " 0.69411765 0.71764706 0.68627451 0.7372549  0.90980392 1.\n",
            " 0.8745098  0.85882353 0.76078431 0.70196078 0.72941176 0.83529412\n",
            " 0.57254902 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.1372549  0.63921569 0.54901961 0.58823529 0.59607843\n",
            " 0.58823529 0.57254902 0.68627451 0.68627451 0.67843137 0.67058824\n",
            " 0.61176471 0.59607843 0.58039216 0.50588235 0.61176471 0.54901961\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.58823529\n",
            " 0.55686275 0.54901961 0.59607843 0.62745098 0.61176471 0.57254902\n",
            " 0.55686275 0.49803922 0.52941176 0.52156863 0.54901961 0.54901961\n",
            " 0.5372549  0.52156863 0.49019608 0.6627451  0.29411765 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.21176471 0.65490196 0.57254902\n",
            " 0.50588235 0.55686275 0.5372549  0.5372549  0.51372549 0.58039216\n",
            " 0.58039216 0.52156863 0.51372549 0.51372549 0.51372549 0.49019608\n",
            " 0.54901961 0.54901961 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.43137255 0.7372549  0.52156863 0.57254902\n",
            " 0.59607843 0.52156863 0.49019608 0.49803922 0.46666667 0.50588235\n",
            " 0.52156863 0.46666667 0.54901961 0.51372549 0.58823529 0.05490196\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.86666667 0.61960784 0.5372549  0.52941176 0.48235294\n",
            " 0.43137255 0.43137255 0.44705882 0.42352941 0.43921569 0.45882353\n",
            " 0.49803922 0.55686275 0.30196078 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.01568627 0.         0.09803922\n",
            " 0.61960784 0.5372549  0.49019608 0.46666667 0.46666667 0.43137255\n",
            " 0.45882353 0.45882353 0.43137255 0.46666667 0.49803922 0.56470588\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.48235294 0.61176471\n",
            " 0.50588235 0.43921569 0.43137255 0.4        0.43921569 0.39215686\n",
            " 0.4745098  0.45882353 0.50588235 0.44705882 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.49019608 0.6627451  0.49803922 0.46666667\n",
            " 0.41568627 0.42352941 0.40784314 0.36862745 0.4745098  0.44705882\n",
            " 0.50588235 0.35686275 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.00784314 0.\n",
            " 0.38431373 0.67058824 0.50588235 0.43921569 0.40784314 0.44705882\n",
            " 0.41568627 0.4        0.43921569 0.40784314 0.52156863 0.25098039\n",
            " 0.         0.01568627 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00784314 0.         0.25882353 0.67843137\n",
            " 0.52941176 0.50588235 0.38431373 0.39215686 0.46666667 0.4\n",
            " 0.42352941 0.38431373 0.52941176 0.23529412 0.         0.01568627\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.00784314 0.         0.21960784 0.67058824 0.52941176 0.49803922\n",
            " 0.39215686 0.42352941 0.45882353 0.33333333 0.41568627 0.43137255\n",
            " 0.52941176 0.25882353 0.         0.01568627 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.20392157 0.58823529 0.50588235 0.43137255 0.39215686 0.35686275\n",
            " 0.4        0.36862745 0.3254902  0.40784314 0.48235294 0.25882353\n",
            " 0.         0.01568627 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00784314 0.         0.25882353 0.65490196\n",
            " 0.54901961 0.58039216 0.58039216 0.49803922 0.5372549  0.59607843\n",
            " 0.57254902 0.57254902 0.58039216 0.37647059 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.17647059 0.48235294 0.36862745 0.40784314\n",
            " 0.37647059 0.46666667 0.4745098  0.41568627 0.38431373 0.43921569\n",
            " 0.34117647 0.44705882 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.41568627 0.34901961 0.22745098 0.19607843 0.14509804 0.19607843\n",
            " 0.25882353 0.21960784 0.19607843 0.29411765 0.29411765 0.5372549\n",
            " 0.08627451 0.         0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00784314 0.         0.11372549 0.58039216 0.44705882\n",
            " 0.41568627 0.49019608 0.34901961 0.39215686 0.52156863 0.45882353\n",
            " 0.51372549 0.51372549 0.51372549 0.49019608 0.43921569 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.39215686 0.41568627 0.44705882 0.35686275 0.5372549\n",
            " 0.24313725 0.4        0.51372549 0.34901961 0.52941176 0.43921569\n",
            " 0.51372549 0.42352941 0.52941176 0.14509804 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.57254902\n",
            " 0.39215686 0.42352941 0.38431373 0.56470588 0.24313725 0.41568627\n",
            " 0.51372549 0.34117647 0.52156863 0.40784314 0.62745098 0.45882353\n",
            " 0.4745098  0.26666667 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.12941176 0.4745098  0.42352941 0.37647059\n",
            " 0.39215686 0.54901961 0.27843137 0.41568627 0.49803922 0.33333333\n",
            " 0.54901961 0.40784314 0.58823529 0.54901961 0.44705882 0.34901961\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.24313725 0.46666667 0.43921569 0.4        0.43137255 0.5372549\n",
            " 0.29411765 0.41568627 0.56470588 0.31764706 0.56470588 0.42352941\n",
            " 0.45882353 0.60392157 0.45882353 0.40784314 0.07058824 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.25882353 0.4745098\n",
            " 0.4        0.43921569 0.45882353 0.51372549 0.28627451 0.40784314\n",
            " 0.61176471 0.30196078 0.5372549  0.52941176 0.3254902  0.70196078\n",
            " 0.50588235 0.4745098  0.1372549  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.33333333 0.49803922 0.31764706 0.49019608\n",
            " 0.52156863 0.46666667 0.30980392 0.39215686 0.6627451  0.3254902\n",
            " 0.50588235 0.68627451 0.23529412 0.63921569 0.52941176 0.57254902\n",
            " 0.15294118 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.41568627 0.50588235 0.24313725 0.54901961 0.56470588 0.42352941\n",
            " 0.33333333 0.3254902  0.61960784 0.33333333 0.50588235 0.68627451\n",
            " 0.18823529 0.57254902 0.52156863 0.52941176 0.25098039 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.45882353 0.46666667\n",
            " 0.30980392 0.54901961 0.59607843 0.4        0.34901961 0.43137255\n",
            " 0.5372549  0.37647059 0.58823529 0.76862745 0.3254902  0.56470588\n",
            " 0.52941176 0.52156863 0.30196078 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.60392157 0.4745098  0.34117647 0.54901961\n",
            " 0.60392157 0.43921569 0.36862745 0.20392157 0.55686275 0.39215686\n",
            " 0.3254902  0.59607843 0.33333333 0.62745098 0.52156863 0.39215686\n",
            " 0.04705882 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.01568627 0.         0.00784314 0.         0.1372549  0.01568627\n",
            " 0.12941176 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "The aL shape , (20,)\n",
            "\n",
            "The aL is  [ -9.10235979  -9.04602022   1.15087581   1.20855587 -23.33038758\n",
            "  -2.81452502  -1.38741389 -20.99128098 -25.06736159   3.67410901\n",
            "   6.75500827  -2.65362298   3.47542086   9.249533    -8.52425795\n",
            "  13.58310261   8.76237218   9.6323757   21.24902954  -4.67863355]\n",
            "\n",
            "The hL shape , (20,)\n",
            "\n",
            "The hL is  [1.11390202e-04 1.17845269e-04 7.59670851e-01 7.70043326e-01\n",
            " 7.37465000e-11 5.65442992e-02 1.99820935e-01 7.64896200e-10\n",
            " 1.29832430e-11 9.75255808e-01 9.98836326e-01 6.57660596e-02\n",
            " 9.69980269e-01 9.99903853e-01 1.98552597e-04 9.99998738e-01\n",
            " 9.99843512e-01 9.99934433e-01 9.99999999e-01 9.20616099e-03]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 2\n",
            "The h(L-1) from previous layer , (20,)\n",
            "\n",
            "The h(L-1) is  [1.11390202e-04 1.17845269e-04 7.59670851e-01 7.70043326e-01\n",
            " 7.37465000e-11 5.65442992e-02 1.99820935e-01 7.64896200e-10\n",
            " 1.29832430e-11 9.75255808e-01 9.98836326e-01 6.57660596e-02\n",
            " 9.69980269e-01 9.99903853e-01 1.98552597e-04 9.99998738e-01\n",
            " 9.99843512e-01 9.99934433e-01 9.99999999e-01 9.20616099e-03]\n",
            "\n",
            "The aL shape , (15,)\n",
            "\n",
            "The aL is  [-0.88657019 -1.61289957  0.88996499 -1.26680888  6.68386615 -2.08508723\n",
            " -1.90830853  0.05416888  1.53981769  2.54182052 -1.15328686 -4.01570456\n",
            " -1.70772302 -2.86050066 -0.74629841]\n",
            "\n",
            "The hL shape , (15,)\n",
            "\n",
            "The hL is  [0.29181813 0.16618644 0.70888295 0.21980401 0.99875063 0.11055474\n",
            " 0.129171   0.51353891 0.82343822 0.92702208 0.23988924 0.01771091\n",
            " 0.15345928 0.05414106 0.32162839]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 3\n",
            "The h(L-1) from previous layer , (15,)\n",
            "\n",
            "The h(L-1) is  [0.29181813 0.16618644 0.70888295 0.21980401 0.99875063 0.11055474\n",
            " 0.129171   0.51353891 0.82343822 0.92702208 0.23988924 0.01771091\n",
            " 0.15345928 0.05414106 0.32162839]\n",
            "\n",
            "The aL shape , (10,)\n",
            "\n",
            "The aL is  [-4.56374566 -0.98625962 -0.76521519 -2.1302617  -1.7867833  -0.48622352\n",
            " -1.07470654 -1.57212131  0.95517287  1.24209581]\n",
            "\n",
            "The hL shape , (10,)\n",
            "\n",
            "The hL is  [0.00124664 0.04460894 0.05564425 0.01420981 0.0200336  0.07355037\n",
            " 0.04083287 0.0248305  0.31086753 0.4141755 ]\n",
            "****************************************************************************************************\n",
            "\n",
            "loss upto datapoint 3 is 15.129349460001928\n",
            "\n",
            " passing  datapoint..4\n",
            "for input layer the hL shape  (784,)\n",
            "For Layer :\n",
            " 1\n",
            "The h(L-1) from previous layer , (784,)\n",
            "\n",
            "The h(L-1) is  [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.10196078\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.74117647 0.80784314 0.73333333 0.1254902  0.         0.\n",
            " 0.         0.10196078 0.85098039 0.88627451 0.76862745 0.04313725\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.75294118 0.89019608\n",
            " 0.91764706 0.95294118 0.90196078 0.57647059 0.9372549  0.94901961\n",
            " 0.91764706 0.85490196 0.81960784 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.67843137 0.88235294 0.84313725 0.91372549\n",
            " 0.99607843 0.         0.76078431 0.94117647 0.85098039 0.86666667\n",
            " 0.74509804 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.54509804 0.89803922 0.83137255 0.88627451 1.         0.\n",
            " 0.63529412 1.         0.83529412 0.88627451 0.78431373 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.38431373 0.90980392\n",
            " 0.82745098 0.84313725 0.97647059 0.18039216 0.63529412 0.96470588\n",
            " 0.83921569 0.90196078 0.72941176 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.2745098  0.89411765 0.83529412 0.8627451\n",
            " 0.87843137 0.98823529 0.9372549  0.85882353 0.85098039 0.90588235\n",
            " 0.67058824 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.17647059 0.87058824 0.83921569 0.85490196 0.84705882 0.82352941\n",
            " 0.84313725 0.85098039 0.79215686 0.87843137 0.6745098  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.09411765 0.99607843\n",
            " 0.83921569 0.82352941 0.82745098 0.83921569 0.84313725 0.83137255\n",
            " 0.79607843 0.86666667 0.65490196 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.99607843 0.84705882 0.84313725\n",
            " 0.85098039 0.85098039 0.84705882 0.84705882 0.80784314 0.88235294\n",
            " 0.58823529 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.96862745 0.84705882 0.83921569 0.85098039 0.84705882\n",
            " 0.83921569 0.83137255 0.79607843 0.88627451 0.53333333 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.96078431\n",
            " 0.84705882 0.83921569 0.84705882 0.85098039 0.84313725 0.82745098\n",
            " 0.8        0.88235294 0.49019608 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.96862745 0.84705882 0.83921569\n",
            " 0.85098039 0.8627451  0.85098039 0.83529412 0.79607843 0.87058824\n",
            " 0.57647059 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.97254902 0.84705882 0.84313725 0.85490196 0.87058824\n",
            " 0.84705882 0.83921569 0.81176471 0.85490196 0.70196078 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.97647059\n",
            " 0.84705882 0.85098039 0.85882353 0.87058824 0.85098039 0.83921569\n",
            " 0.82352941 0.84313725 0.82745098 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.14901961 1.         0.83921569 0.85490196\n",
            " 0.85882353 0.87843137 0.85490196 0.84313725 0.82745098 0.82745098\n",
            " 0.90588235 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.30980392 0.89019608 0.81960784 0.85882353 0.85882353 0.89019608\n",
            " 0.85882353 0.84313725 0.83529412 0.80784314 0.99607843 0.22745098\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.57254902 0.88627451\n",
            " 0.82745098 0.8627451  0.85882353 0.89411765 0.85490196 0.84313725\n",
            " 0.84705882 0.80392157 0.85882353 0.63921569 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.79215686 0.86666667 0.83921569 0.86666667\n",
            " 0.85882353 0.90588235 0.85490196 0.84313725 0.85490196 0.83529412\n",
            " 0.83137255 0.8627451  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.91764706 0.85098039 0.84705882 0.8627451  0.85882353 0.91764706\n",
            " 0.85098039 0.84313725 0.85490196 0.84705882 0.8745098  0.96862745\n",
            " 0.02745098 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.06666667 0.99607843 0.83137255\n",
            " 0.85882353 0.85882353 0.8627451  0.91372549 0.83921569 0.84705882\n",
            " 0.85882353 0.87058824 0.6        0.93333333 0.22745098 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.25882353 1.         0.81568627 0.8627451  0.85882353\n",
            " 0.87058824 0.94509804 0.8627451  0.85490196 0.85490196 0.85490196\n",
            " 0.75294118 0.94901961 0.38823529 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.55686275\n",
            " 0.92156863 0.79607843 0.85490196 0.84705882 0.90588235 0.94901961\n",
            " 0.88235294 0.91372549 0.85882353 0.83921569 0.84705882 0.93333333\n",
            " 0.56470588 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.69411765 0.97254902 0.89019608\n",
            " 0.89803922 0.82745098 1.         0.29803922 0.         0.96862745\n",
            " 0.95294118 0.90196078 0.90196078 0.97647059 0.73333333 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.39607843 0.94509804 0.89411765 0.89411765 0.8627451\n",
            " 1.         0.25098039 0.         0.95294118 0.92941176 0.90196078\n",
            " 0.89019608 0.94509804 0.55686275 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 1.         0.94901961 0.87058824 0.85490196 1.         0.24313725\n",
            " 0.         0.8745098  0.93333333 0.88235294 0.93333333 1.\n",
            " 0.12156863 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.17647059 1.\n",
            " 0.94901961 0.92156863 1.         0.32941176 0.         0.96470588\n",
            " 1.         0.94901961 1.         0.2745098  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.23921569 0.4\n",
            " 0.65882353 0.09803922 0.         0.54509804 0.63137255 0.29019608\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "The aL shape , (20,)\n",
            "\n",
            "The aL is  [-2.50198635e+01 -5.27130139e+00  1.74331485e+01  7.32596548e+00\n",
            " -3.06200735e+01 -1.04202830e+00  1.58353606e-02 -1.75737542e+01\n",
            " -2.11581293e+01  3.93708142e+00  2.86004825e+00  1.06785964e+01\n",
            "  1.10339125e-01  1.09173379e+01  3.90269059e+00  1.51398601e+01\n",
            "  1.76245656e+01  2.13549151e+01  3.49139490e+01  4.49960191e+00]\n",
            "\n",
            "The hL shape , (20,)\n",
            "\n",
            "The hL is  [1.36148020e-11 5.11066797e-03 9.99999973e-01 9.99342209e-01\n",
            " 5.03351120e-14 2.60758822e-01 5.03958757e-01 2.33246693e-08\n",
            " 6.47353034e-10 9.80868110e-01 9.45835771e-01 9.99976968e-01\n",
            " 5.27556829e-01 9.99981859e-01 9.80211950e-01 9.99999734e-01\n",
            " 9.99999978e-01 9.99999999e-01 1.00000000e+00 9.89008731e-01]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 2\n",
            "The h(L-1) from previous layer , (20,)\n",
            "\n",
            "The h(L-1) is  [1.36148020e-11 5.11066797e-03 9.99999973e-01 9.99342209e-01\n",
            " 5.03351120e-14 2.60758822e-01 5.03958757e-01 2.33246693e-08\n",
            " 6.47353034e-10 9.80868110e-01 9.45835771e-01 9.99976968e-01\n",
            " 5.27556829e-01 9.99981859e-01 9.80211950e-01 9.99999734e-01\n",
            " 9.99999978e-01 9.99999999e-01 1.00000000e+00 9.89008731e-01]\n",
            "\n",
            "The aL shape , (15,)\n",
            "\n",
            "The aL is  [ 1.58277795  2.04882189 -0.67942178 -3.47385834  3.72207341 -2.99470164\n",
            " -1.45576643  0.18318542  0.04820542  1.88225604 -1.82857736 -4.36640403\n",
            " -1.85343528 -4.49893319 -3.72233399]\n",
            "\n",
            "The hL shape , (15,)\n",
            "\n",
            "The hL is  [0.82959758 0.88582852 0.33639037 0.03006526 0.97638727 0.04766581\n",
            " 0.18911569 0.54566872 0.51204902 0.86787005 0.13840784 0.01253763\n",
            " 0.13547006 0.01099854 0.02360672]\n",
            "****************************************************************************************************\n",
            "For Layer :\n",
            " 3\n",
            "The h(L-1) from previous layer , (15,)\n",
            "\n",
            "The h(L-1) is  [0.82959758 0.88582852 0.33639037 0.03006526 0.97638727 0.04766581\n",
            " 0.18911569 0.54566872 0.51204902 0.86787005 0.13840784 0.01253763\n",
            " 0.13547006 0.01099854 0.02360672]\n",
            "\n",
            "The aL shape , (10,)\n",
            "\n",
            "The aL is  [-4.05847337 -1.07889253  1.00785046 -1.42463702 -2.01215718 -1.90444533\n",
            " -1.06990316  1.68435584  0.49441602  0.45214672]\n",
            "\n",
            "The hL shape , (10,)\n",
            "\n",
            "The hL is  [0.00137506 0.0270605  0.21807045 0.01915054 0.01064202 0.01185231\n",
            " 0.02730486 0.42894278 0.13050137 0.12510013]\n",
            "****************************************************************************************************\n",
            "\n",
            "loss upto datapoint 4 is 18.128194318788395\n",
            "Loss is :  18.128194318788395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxRTXpUtJEHF",
        "outputId": "b33db185-ba97-4b49-d2d2-78fdc2148df2"
      },
      "source": [
        "print(\"cumulative Loss is :\",arch1.loss)"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cumulative Loss is : 18.128194318788395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ8eIfk4Vo5N",
        "outputId": "278aab35-812c-435a-e9cf-1e8cd5eb46c2"
      },
      "source": [
        "arch1.Back_Propogation(Y_sample)\n",
        "\n",
        "\n",
        "print(\"Gradients For various layers:\\n\")\n",
        "for i in range(1,arch1.num_hlayers+2):\n",
        "  print(\"Layer_number : \",i)\n",
        "  arch1.Layers[i].show_gradients()\n",
        "  print(\"**\"*50)"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradients For various layers:\n",
            "\n",
            "Layer_number :  1\n",
            "del_h shape  (20,)\n",
            "del_h \n",
            " [ -1.33828523  -4.10233671  15.5746545    5.87373503   3.57934998\n",
            "  -3.1600109   -7.5708088   11.17794677  -4.68170729   1.34580625\n",
            "  12.27579626  11.24025536  -3.25558826  14.74063175  12.58190731\n",
            "   4.73977805  27.89521423 -10.79278353  -2.27306188   5.74156541]\n",
            "del_a shape  (20,)\n",
            "del_a \n",
            " [-1.82204884e-11 -2.08585322e-02  4.18117345e-07  3.86114783e-03\n",
            "  1.80166982e-13 -6.09135261e-01 -1.89258355e+00  2.60721905e-07\n",
            " -3.03071741e-09  2.52552130e-02  6.28894750e-01  2.58881293e-04\n",
            " -8.11424841e-01  2.67399590e-04  2.44044755e-01  1.26066604e-06\n",
            "  6.18412242e-07 -5.73867656e-09 -1.51416338e-15  6.24134639e-02]\n",
            "delW shape  (20, 784)\n",
            "delW \n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "delb shape  (20,)\n",
            "delb \n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "****************************************************************************************************\n",
            "Layer_number :  2\n",
            "del_h shape  (15,)\n",
            "del_h \n",
            " [  4.26992054   8.9869701    5.88003048  -8.8169026   16.82444374\n",
            "   2.89816894  -0.40554895   3.30923886  -0.6098179    5.92603017\n",
            "  -1.90018968 -12.25816187  -4.11673677  12.69316878   1.71621102]\n",
            "del_a shape  (15,)\n",
            "del_a \n",
            " [ 0.60361917  0.90890936  1.31261031 -0.25711272  0.38789036  0.13155885\n",
            " -0.06219132  0.82040786 -0.15236594  0.67954754 -0.22659972 -0.15176139\n",
            " -0.48214366  0.13807087  0.03955771]\n",
            "delW shape  (15, 20)\n",
            "delW \n",
            " [[ 8.21815543e-12  3.08489714e-03  6.03619150e-01  6.03222111e-01\n",
            "   3.03832384e-14  1.57399023e-01  3.04199165e-01  1.40792174e-08\n",
            "   3.90754698e-10  5.92070791e-01  5.70924600e-01  6.03605264e-01\n",
            "   3.18443413e-01  6.03608216e-01  5.91674720e-01  6.03619006e-01\n",
            "   6.03619153e-01  6.03619166e-01  6.03619166e-01  5.96984626e-01]\n",
            " [ 1.23746209e-11  4.64513395e-03  9.08909334e-01  9.08311486e-01\n",
            "   4.57500544e-14  2.37006133e-01  4.58052831e-01  2.12000102e-08\n",
            "   5.88385230e-10  8.91520204e-01  8.59678984e-01  9.08888424e-01\n",
            "   4.79501339e-01  9.08892870e-01  8.90923814e-01  9.08909116e-01\n",
            "   9.08909338e-01  9.08909357e-01  9.08909358e-01  8.98919291e-01]\n",
            " [ 1.78709294e-11  6.70831546e-03  1.31261027e+00  1.31174688e+00\n",
            "   6.60703868e-14  3.42274717e-01  6.61501459e-01  3.06162013e-08\n",
            "   8.49722264e-10  1.28749759e+00  1.24151378e+00  1.31258007e+00\n",
            "   6.92476531e-01  1.31258650e+00  1.28663631e+00  1.31260996e+00\n",
            "   1.31261028e+00  1.31261031e+00  1.31261031e+00  1.29818305e+00]\n",
            " [-3.50053876e-12 -1.31401774e-03 -2.57112712e-01 -2.56943593e-01\n",
            "  -1.29417975e-14 -6.70444097e-02 -1.29574206e-01 -5.99706913e-09\n",
            "  -1.66442699e-10 -2.52193667e-01 -2.43186407e-01 -2.57106797e-01\n",
            "  -1.35641571e-01 -2.57108055e-01 -2.52024960e-01 -2.57112651e-01\n",
            "  -2.57112713e-01 -2.57112719e-01 -2.57112719e-01 -2.54286724e-01]\n",
            " [ 5.28105046e-12  1.98237885e-03  3.87890351e-01  3.87635210e-01\n",
            "   1.95245048e-14  1.01145833e-01  1.95480744e-01  9.04741438e-09\n",
            "   2.51102002e-10  3.80469285e-01  3.66880579e-01  3.87881427e-01\n",
            "   2.04634209e-01  3.87883325e-01  3.80214767e-01  3.87890258e-01\n",
            "   3.87890353e-01  3.87890361e-01  3.87890361e-01  3.83626954e-01]\n",
            " [ 1.79114763e-12  6.72353578e-04  1.31558842e-01  1.31472307e-01\n",
            "   6.62202923e-15  3.43051295e-02  6.63002323e-02  3.06856656e-09\n",
            "   8.51650177e-11  1.29041876e-01  1.24433062e-01  1.31555815e-01\n",
            "   6.94047674e-02  1.31556459e-01  1.28955552e-01  1.31558811e-01\n",
            "   1.31558843e-01  1.31558845e-01  1.31558846e-01  1.30112847e-01]\n",
            " [-8.46722453e-13 -3.17839167e-04 -6.21913144e-02 -6.21504072e-02\n",
            "  -3.13040686e-15 -1.62169343e-02 -3.13418584e-02 -1.45059188e-09\n",
            "  -4.02597371e-11 -6.10014786e-02 -5.88227714e-02 -6.21898836e-02\n",
            "  -3.28094535e-02 -6.21901878e-02 -6.09606712e-02 -6.21912995e-02\n",
            "  -6.21913147e-02 -6.21913160e-02 -6.21913160e-02 -6.15077545e-02]\n",
            " [ 1.11696906e-11  4.19283218e-03  8.20407838e-01  8.19868203e-01\n",
            "   4.12953215e-14  2.13928587e-01  4.13451726e-01  1.91357420e-08\n",
            "   5.31093517e-10  8.04711907e-01  7.75971101e-01  8.20388964e-01\n",
            "   4.32811769e-01  8.20392977e-01  8.04173588e-01  8.20407642e-01\n",
            "   8.20407842e-01  8.20407860e-01  8.20407860e-01  8.11390536e-01]\n",
            " [-2.07443212e-12 -7.78691738e-04 -1.52365938e-01 -1.52265717e-01\n",
            "  -7.66935674e-15 -3.97307634e-02 -7.67861506e-02 -3.55388519e-09\n",
            "  -9.86345545e-11 -1.49450893e-01 -1.44113158e-01 -1.52362432e-01\n",
            "  -8.03816930e-02 -1.52363178e-01 -1.49350917e-01 -1.52365901e-01\n",
            "  -1.52365938e-01 -1.52365942e-01 -1.52365942e-01 -1.50691247e-01]\n",
            " [ 9.25190517e-12  3.47294184e-03  6.79547519e-01  6.79100538e-01\n",
            "   3.42051014e-14  1.77198015e-01  3.42463933e-01  1.58502216e-08\n",
            "   4.39907160e-10  6.66546509e-01  6.42740370e-01  6.79531886e-01\n",
            "   3.58499944e-01  6.79535210e-01  6.66100617e-01  6.79547357e-01\n",
            "   6.79547523e-01  6.79547537e-01  6.79547538e-01  6.72078448e-01]\n",
            " [-3.08511038e-12 -1.15807595e-03 -2.26599718e-01 -2.26450669e-01\n",
            "  -1.14059225e-14 -5.90878771e-02 -1.14196915e-01 -5.28536362e-09\n",
            "  -1.46690019e-10 -2.22264443e-01 -2.14326125e-01 -2.26594505e-01\n",
            "  -1.19544232e-01 -2.26595614e-01 -2.22115758e-01 -2.26599664e-01\n",
            "  -2.26599719e-01 -2.26599724e-01 -2.26599724e-01 -2.24109106e-01]\n",
            " [-2.06620124e-12 -7.75602062e-04 -1.51761383e-01 -1.51661560e-01\n",
            "  -7.63892644e-15 -3.95731206e-02 -7.64814802e-02 -3.53978417e-09\n",
            "  -9.82431945e-11 -1.48857905e-01 -1.43541349e-01 -1.51757892e-01\n",
            "  -8.00627563e-02 -1.51758634e-01 -1.48758325e-01 -1.51761347e-01\n",
            "  -1.51761384e-01 -1.51761387e-01 -1.51761387e-01 -1.50093337e-01]\n",
            " [-6.56429043e-12 -2.46407615e-03 -4.82143645e-01 -4.81826508e-01\n",
            "  -2.42687550e-14 -1.25723212e-01 -2.42980519e-01 -1.12458413e-08\n",
            "  -3.12117159e-10 -4.72919338e-01 -4.56028718e-01 -4.82132553e-01\n",
            "  -2.54358179e-01 -4.82134911e-01 -4.72602975e-01 -4.82143529e-01\n",
            "  -4.82143647e-01 -4.82143657e-01 -4.82143658e-01 -4.76844287e-01]\n",
            " [ 1.87980755e-12  7.05634373e-04  1.38070866e-01  1.37980048e-01\n",
            "   6.94981270e-15  3.60031973e-02  6.95820240e-02  3.22045737e-09\n",
            "   8.93805965e-11  1.35429313e-01  1.30592368e-01  1.38067690e-01\n",
            "   7.28402303e-02  1.38068365e-01  1.35338717e-01  1.38070833e-01\n",
            "   1.38070867e-01  1.38070870e-01  1.38070870e-01  1.36553296e-01]\n",
            " [ 5.38570384e-13  2.02166320e-04  3.95577086e-02  3.95316890e-02\n",
            "   1.99114175e-15  1.03150218e-02  1.99354542e-02  9.22670494e-10\n",
            "   2.56078034e-11  3.88008959e-02  3.74150968e-02  3.95567986e-02\n",
            "   2.08689399e-02  3.95569921e-02  3.87749397e-02  3.95576991e-02\n",
            "   3.95577088e-02  3.95577096e-02  3.95577097e-02  3.91229202e-02]]\n",
            "delb shape  (15,)\n",
            "delb \n",
            " [[ 8.21815543e-12  3.08489714e-03  6.03619150e-01  6.03222111e-01\n",
            "   3.03832384e-14  1.57399023e-01  3.04199165e-01  1.40792174e-08\n",
            "   3.90754698e-10  5.92070791e-01  5.70924600e-01  6.03605264e-01\n",
            "   3.18443413e-01  6.03608216e-01  5.91674720e-01  6.03619006e-01\n",
            "   6.03619153e-01  6.03619166e-01  6.03619166e-01  5.96984626e-01]\n",
            " [ 1.23746209e-11  4.64513395e-03  9.08909334e-01  9.08311486e-01\n",
            "   4.57500544e-14  2.37006133e-01  4.58052831e-01  2.12000102e-08\n",
            "   5.88385230e-10  8.91520204e-01  8.59678984e-01  9.08888424e-01\n",
            "   4.79501339e-01  9.08892870e-01  8.90923814e-01  9.08909116e-01\n",
            "   9.08909338e-01  9.08909357e-01  9.08909358e-01  8.98919291e-01]\n",
            " [ 1.78709294e-11  6.70831546e-03  1.31261027e+00  1.31174688e+00\n",
            "   6.60703868e-14  3.42274717e-01  6.61501459e-01  3.06162013e-08\n",
            "   8.49722264e-10  1.28749759e+00  1.24151378e+00  1.31258007e+00\n",
            "   6.92476531e-01  1.31258650e+00  1.28663631e+00  1.31260996e+00\n",
            "   1.31261028e+00  1.31261031e+00  1.31261031e+00  1.29818305e+00]\n",
            " [-3.50053876e-12 -1.31401774e-03 -2.57112712e-01 -2.56943593e-01\n",
            "  -1.29417975e-14 -6.70444097e-02 -1.29574206e-01 -5.99706913e-09\n",
            "  -1.66442699e-10 -2.52193667e-01 -2.43186407e-01 -2.57106797e-01\n",
            "  -1.35641571e-01 -2.57108055e-01 -2.52024960e-01 -2.57112651e-01\n",
            "  -2.57112713e-01 -2.57112719e-01 -2.57112719e-01 -2.54286724e-01]\n",
            " [ 5.28105046e-12  1.98237885e-03  3.87890351e-01  3.87635210e-01\n",
            "   1.95245048e-14  1.01145833e-01  1.95480744e-01  9.04741438e-09\n",
            "   2.51102002e-10  3.80469285e-01  3.66880579e-01  3.87881427e-01\n",
            "   2.04634209e-01  3.87883325e-01  3.80214767e-01  3.87890258e-01\n",
            "   3.87890353e-01  3.87890361e-01  3.87890361e-01  3.83626954e-01]\n",
            " [ 1.79114763e-12  6.72353578e-04  1.31558842e-01  1.31472307e-01\n",
            "   6.62202923e-15  3.43051295e-02  6.63002323e-02  3.06856656e-09\n",
            "   8.51650177e-11  1.29041876e-01  1.24433062e-01  1.31555815e-01\n",
            "   6.94047674e-02  1.31556459e-01  1.28955552e-01  1.31558811e-01\n",
            "   1.31558843e-01  1.31558845e-01  1.31558846e-01  1.30112847e-01]\n",
            " [-8.46722453e-13 -3.17839167e-04 -6.21913144e-02 -6.21504072e-02\n",
            "  -3.13040686e-15 -1.62169343e-02 -3.13418584e-02 -1.45059188e-09\n",
            "  -4.02597371e-11 -6.10014786e-02 -5.88227714e-02 -6.21898836e-02\n",
            "  -3.28094535e-02 -6.21901878e-02 -6.09606712e-02 -6.21912995e-02\n",
            "  -6.21913147e-02 -6.21913160e-02 -6.21913160e-02 -6.15077545e-02]\n",
            " [ 1.11696906e-11  4.19283218e-03  8.20407838e-01  8.19868203e-01\n",
            "   4.12953215e-14  2.13928587e-01  4.13451726e-01  1.91357420e-08\n",
            "   5.31093517e-10  8.04711907e-01  7.75971101e-01  8.20388964e-01\n",
            "   4.32811769e-01  8.20392977e-01  8.04173588e-01  8.20407642e-01\n",
            "   8.20407842e-01  8.20407860e-01  8.20407860e-01  8.11390536e-01]\n",
            " [-2.07443212e-12 -7.78691738e-04 -1.52365938e-01 -1.52265717e-01\n",
            "  -7.66935674e-15 -3.97307634e-02 -7.67861506e-02 -3.55388519e-09\n",
            "  -9.86345545e-11 -1.49450893e-01 -1.44113158e-01 -1.52362432e-01\n",
            "  -8.03816930e-02 -1.52363178e-01 -1.49350917e-01 -1.52365901e-01\n",
            "  -1.52365938e-01 -1.52365942e-01 -1.52365942e-01 -1.50691247e-01]\n",
            " [ 9.25190517e-12  3.47294184e-03  6.79547519e-01  6.79100538e-01\n",
            "   3.42051014e-14  1.77198015e-01  3.42463933e-01  1.58502216e-08\n",
            "   4.39907160e-10  6.66546509e-01  6.42740370e-01  6.79531886e-01\n",
            "   3.58499944e-01  6.79535210e-01  6.66100617e-01  6.79547357e-01\n",
            "   6.79547523e-01  6.79547537e-01  6.79547538e-01  6.72078448e-01]\n",
            " [-3.08511038e-12 -1.15807595e-03 -2.26599718e-01 -2.26450669e-01\n",
            "  -1.14059225e-14 -5.90878771e-02 -1.14196915e-01 -5.28536362e-09\n",
            "  -1.46690019e-10 -2.22264443e-01 -2.14326125e-01 -2.26594505e-01\n",
            "  -1.19544232e-01 -2.26595614e-01 -2.22115758e-01 -2.26599664e-01\n",
            "  -2.26599719e-01 -2.26599724e-01 -2.26599724e-01 -2.24109106e-01]\n",
            " [-2.06620124e-12 -7.75602062e-04 -1.51761383e-01 -1.51661560e-01\n",
            "  -7.63892644e-15 -3.95731206e-02 -7.64814802e-02 -3.53978417e-09\n",
            "  -9.82431945e-11 -1.48857905e-01 -1.43541349e-01 -1.51757892e-01\n",
            "  -8.00627563e-02 -1.51758634e-01 -1.48758325e-01 -1.51761347e-01\n",
            "  -1.51761384e-01 -1.51761387e-01 -1.51761387e-01 -1.50093337e-01]\n",
            " [-6.56429043e-12 -2.46407615e-03 -4.82143645e-01 -4.81826508e-01\n",
            "  -2.42687550e-14 -1.25723212e-01 -2.42980519e-01 -1.12458413e-08\n",
            "  -3.12117159e-10 -4.72919338e-01 -4.56028718e-01 -4.82132553e-01\n",
            "  -2.54358179e-01 -4.82134911e-01 -4.72602975e-01 -4.82143529e-01\n",
            "  -4.82143647e-01 -4.82143657e-01 -4.82143658e-01 -4.76844287e-01]\n",
            " [ 1.87980755e-12  7.05634373e-04  1.38070866e-01  1.37980048e-01\n",
            "   6.94981270e-15  3.60031973e-02  6.95820240e-02  3.22045737e-09\n",
            "   8.93805965e-11  1.35429313e-01  1.30592368e-01  1.38067690e-01\n",
            "   7.28402303e-02  1.38068365e-01  1.35338717e-01  1.38070833e-01\n",
            "   1.38070867e-01  1.38070870e-01  1.38070870e-01  1.36553296e-01]\n",
            " [ 5.38570384e-13  2.02166320e-04  3.95577086e-02  3.95316890e-02\n",
            "   1.99114175e-15  1.03150218e-02  1.99354542e-02  9.22670494e-10\n",
            "   2.56078034e-11  3.88008959e-02  3.74150968e-02  3.95567986e-02\n",
            "   2.08689399e-02  3.95569921e-02  3.87749397e-02  3.95576991e-02\n",
            "   3.95577088e-02  3.95577096e-02  3.95577097e-02  3.91229202e-02]]\n",
            "****************************************************************************************************\n",
            "Layer_number :  3\n",
            "dely_hat shape  (10,)\n",
            "dely_hat \n",
            " [-6746.63123568     0.             0.           -70.37393748\n",
            "     0.             0.             0.             0.\n",
            "     0.          -149.66137367]\n",
            "del_a shape  (10,)\n",
            "del_a \n",
            " [-2.99495775  0.12492128  1.06545818 -0.88201055  0.05326641  0.11764947\n",
            "  0.26904603  0.98465916  1.50924923 -0.24728147]\n",
            "delW shape  (10, 15)\n",
            "delW \n",
            " [[-2.48460971e+00 -2.65301900e+00 -1.00747494e+00 -9.00441918e-02\n",
            "  -2.92423862e+00 -1.42757088e-01 -5.66393510e-01 -1.63425476e+00\n",
            "  -1.53356519e+00 -2.59923412e+00 -4.14525625e-01 -3.75496662e-02\n",
            "  -4.05727104e-01 -3.29401653e-02 -7.07011325e-02]\n",
            " [ 1.03634393e-01  1.10658835e-01  4.20223159e-02  3.75579117e-03\n",
            "   1.21971549e-01  5.95447411e-03  2.36245748e-02  6.81656358e-02\n",
            "   6.39658202e-02  1.08415438e-01  1.72900844e-02  1.56621656e-03\n",
            "   1.69230935e-02  1.37395183e-03  2.94898187e-03]\n",
            " [ 8.83901530e-01  9.43813245e-01  3.58409869e-01  3.20332802e-02\n",
            "   1.04029980e+00  5.07859273e-02  2.01494862e-01  5.81387200e-01\n",
            "   5.45566819e-01  9.24679238e-01  1.47467762e-01  1.33583183e-02\n",
            "   1.44337683e-01  1.17184853e-02  2.51519741e-02]\n",
            " [-7.31713824e-01 -7.81310106e-01 -2.96699855e-01 -2.65178791e-02\n",
            "  -8.61183878e-01 -4.20417477e-02 -1.66802037e-01 -4.81285569e-01\n",
            "  -4.51632642e-01 -7.65470539e-01 -1.22077173e-01 -1.10583202e-02\n",
            "  -1.19486022e-01 -9.70082914e-03 -2.08213772e-02]\n",
            " [ 4.41896869e-02  4.71849073e-02  1.79183080e-02  1.60146868e-03\n",
            "   5.20086469e-02  2.53898670e-03  1.00735145e-02  2.90658149e-02\n",
            "   2.72750143e-02  4.62283236e-02  7.37248892e-03  6.67834463e-04\n",
            "   7.21600404e-03  5.85852813e-04  1.25744534e-03]\n",
            " [ 9.76017195e-02  1.04217260e-01  3.95761499e-02  3.53716237e-03\n",
            "   1.14871449e-01  5.60785751e-03  2.22493619e-02  6.41976379e-02\n",
            "   6.02422983e-02  1.02104455e-01  1.62836093e-02  1.47504535e-03\n",
            "   1.59379813e-02  1.29397255e-03  2.77731833e-03]\n",
            " [ 2.23199935e-01  2.38328646e-01  9.05044923e-02  8.08893954e-03\n",
            "   2.62693117e-01  1.28242969e-02  5.08808261e-02  1.46810001e-01\n",
            "   1.37764756e-01  2.33496988e-01  3.72380789e-02  3.37319902e-03\n",
            "   3.64476814e-02  2.95911374e-03  6.35129456e-03]\n",
            " [ 8.16870861e-01  8.72239171e-01  3.31229857e-01  2.96040365e-02\n",
            "   9.61408672e-01  4.69345767e-02  1.86214500e-01  5.37297703e-01\n",
            "   5.04193761e-01  8.54556191e-01  1.36284545e-01  1.23452903e-02\n",
            "   1.33391835e-01  1.08298140e-02  2.32445743e-02]\n",
            " [ 1.25206951e+00  1.33693602e+00  5.07696904e-01  4.53759748e-02\n",
            "   1.47361174e+00  7.19395874e-02  2.85422714e-01  8.23550094e-01\n",
            "   7.72809594e-01  1.30983220e+00  2.08891922e-01  1.89224055e-02\n",
            "   2.04458083e-01  1.65995394e-02  3.56284258e-02]\n",
            " [-2.05144106e-01 -2.19048976e-01 -8.31831031e-02 -7.43458226e-03\n",
            "  -2.41442476e-01 -1.17868714e-02 -4.67648058e-02 -1.34933761e-01\n",
            "  -1.26620233e-01 -2.14608177e-01 -3.42256929e-02 -3.10032303e-03\n",
            "  -3.34992349e-02 -2.71973531e-03 -5.83750461e-03]]\n",
            "delb shape  (10,)\n",
            "delb \n",
            " [[-2.48460971e+00 -2.65301900e+00 -1.00747494e+00 -9.00441918e-02\n",
            "  -2.92423862e+00 -1.42757088e-01 -5.66393510e-01 -1.63425476e+00\n",
            "  -1.53356519e+00 -2.59923412e+00 -4.14525625e-01 -3.75496662e-02\n",
            "  -4.05727104e-01 -3.29401653e-02 -7.07011325e-02]\n",
            " [ 1.03634393e-01  1.10658835e-01  4.20223159e-02  3.75579117e-03\n",
            "   1.21971549e-01  5.95447411e-03  2.36245748e-02  6.81656358e-02\n",
            "   6.39658202e-02  1.08415438e-01  1.72900844e-02  1.56621656e-03\n",
            "   1.69230935e-02  1.37395183e-03  2.94898187e-03]\n",
            " [ 8.83901530e-01  9.43813245e-01  3.58409869e-01  3.20332802e-02\n",
            "   1.04029980e+00  5.07859273e-02  2.01494862e-01  5.81387200e-01\n",
            "   5.45566819e-01  9.24679238e-01  1.47467762e-01  1.33583183e-02\n",
            "   1.44337683e-01  1.17184853e-02  2.51519741e-02]\n",
            " [-7.31713824e-01 -7.81310106e-01 -2.96699855e-01 -2.65178791e-02\n",
            "  -8.61183878e-01 -4.20417477e-02 -1.66802037e-01 -4.81285569e-01\n",
            "  -4.51632642e-01 -7.65470539e-01 -1.22077173e-01 -1.10583202e-02\n",
            "  -1.19486022e-01 -9.70082914e-03 -2.08213772e-02]\n",
            " [ 4.41896869e-02  4.71849073e-02  1.79183080e-02  1.60146868e-03\n",
            "   5.20086469e-02  2.53898670e-03  1.00735145e-02  2.90658149e-02\n",
            "   2.72750143e-02  4.62283236e-02  7.37248892e-03  6.67834463e-04\n",
            "   7.21600404e-03  5.85852813e-04  1.25744534e-03]\n",
            " [ 9.76017195e-02  1.04217260e-01  3.95761499e-02  3.53716237e-03\n",
            "   1.14871449e-01  5.60785751e-03  2.22493619e-02  6.41976379e-02\n",
            "   6.02422983e-02  1.02104455e-01  1.62836093e-02  1.47504535e-03\n",
            "   1.59379813e-02  1.29397255e-03  2.77731833e-03]\n",
            " [ 2.23199935e-01  2.38328646e-01  9.05044923e-02  8.08893954e-03\n",
            "   2.62693117e-01  1.28242969e-02  5.08808261e-02  1.46810001e-01\n",
            "   1.37764756e-01  2.33496988e-01  3.72380789e-02  3.37319902e-03\n",
            "   3.64476814e-02  2.95911374e-03  6.35129456e-03]\n",
            " [ 8.16870861e-01  8.72239171e-01  3.31229857e-01  2.96040365e-02\n",
            "   9.61408672e-01  4.69345767e-02  1.86214500e-01  5.37297703e-01\n",
            "   5.04193761e-01  8.54556191e-01  1.36284545e-01  1.23452903e-02\n",
            "   1.33391835e-01  1.08298140e-02  2.32445743e-02]\n",
            " [ 1.25206951e+00  1.33693602e+00  5.07696904e-01  4.53759748e-02\n",
            "   1.47361174e+00  7.19395874e-02  2.85422714e-01  8.23550094e-01\n",
            "   7.72809594e-01  1.30983220e+00  2.08891922e-01  1.89224055e-02\n",
            "   2.04458083e-01  1.65995394e-02  3.56284258e-02]\n",
            " [-2.05144106e-01 -2.19048976e-01 -8.31831031e-02 -7.43458226e-03\n",
            "  -2.41442476e-01 -1.17868714e-02 -4.67648058e-02 -1.34933761e-01\n",
            "  -1.26620233e-01 -2.14608177e-01 -3.42256929e-02 -3.10032303e-03\n",
            "  -3.34992349e-02 -2.71973531e-03 -5.83750461e-03]]\n",
            "****************************************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtmOHUHaxKva"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}